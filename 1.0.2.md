# v1.0.2 Planning (Playwright Research)

Date: 2026-02-16

## Goal
Define a focused, high-impact feature set for `v1.0.2` based on what developers are actively asking for in agentic coding products.

## Delivery Status (Updated: 2026-02-17)

- [x] P0.1 Live Development Commentary Stream
  - Shipped in `970f1e3` (`feat: stream live development commentary in execution timeline`)
  - Commentary is now streamed as a separate protocol event and shown in timeline UI.
- [x] P0.2 Agent Anti-Stall + Auto-Recovery
  - Shipped in `e81c073` (`feat: add anti-stall recovery with auto-finalize fallback`)
  - Detects repeated tool loops, no-progress streaks, and stream timeouts; applies backoff and recovery.
- [x] P0.3 Execution Transparency Panel
  - Shipped in `c567b20` (`feat: add execution transparency panel and autonomy enforcement`)
  - Shows active model/provider, current step, elapsed runtime, token/cost estimate, recent tool calls, and "why this action".
- [x] P0.4 Safer Autonomy Modes
  - Shipped in `c567b20` (`feat: add execution transparency panel and autonomy enforcement`)
  - Adds `read-only`, `review-required`, `auto-apply-safe`, `full-auto` with runtime enforcement and persisted mode selection.
- [x] P0.5 Reliability Guardrails for Web/Tool Tasks
  - Added cross-provider schema regression suite:
    - `app/lib/.server/llm/tools/tool-schema-compatibility.spec.ts`
    - `tests/api.system.tool-schema-matrix.spec.ts`
  - Added live compatibility matrix endpoint: `/api/system/tool-schema-matrix`
  - Standardized strict-compatible schema validation for `web_search` and `web_browse` across strict and standard provider profiles.
- [x] P1.6 Persistent Project Memory (Scoped)
  - Added scoped memory store and reuse pipeline:
    - `app/lib/.server/llm/project-memory.ts`
    - persisted client handoff via stream data event `project-memory`
  - Memory is injected back into build prompts for context reuse.
- [x] P1.7 Sub-Agent Framework (Minimal)
  - Added feature-flagged planner/worker flow in `api.chat`:
    - planner sub-agent pre-plans execution
    - worker agent executes with plan context
  - Controlled by `BOLT_SUB_AGENTS_ENABLED=true`.
- Validation gate for current `main` push:
  - `pnpm run typecheck` passed
  - `pnpm run lint` passed
  - `pnpm test` passed
  - `pnpm run build:highmem` passed
  - E2E smoke (strict OpenAI path on `https://alpha1.bolt.gives`) passed
  - E2E smoke (standard OpenAI model path on `https://alpha1.bolt.gives`) passed

## How This Was Researched
Used Bolt.gives' Playwright-powered web browsing/search service to gather current requests from:
- Cursor Ideas forum
- Windsurf feature-request board
- OpenAI Codex GitHub issues
- Hacker News threads on coding agents
- GitHub Copilot public pages/discussions

## What People Are Asking For (Patterns)
1. Better agent reliability and fewer stuck loops.
- Users report agents getting stuck, needing manual "continue", or looping.
- Evidence: Cursor Ideas/Feedback topics and Windsurf "Cascade error" / "continue" complaints.

2. Transparent execution: show what the agent is doing and why.
- Users want visibility into plan, progress, model/tool usage, and decision trail.
- Evidence: requests around planning mode, model selection visibility, and repeated community concerns about trust and boundaries.

3. Stronger repo-scale context and multi-repo workflows.
- Users want persistent memory/knowledge graph and cross-repo background work.
- Evidence: Cursor Ideas requests for persistent knowledge graph and multi-repository background mode.

4. Sub-agents/plugins/skills as first-class workflow primitives.
- Users want manager/worker patterns and pluggable agent capabilities.
- Evidence: Cursor requests for agent plugins/sub-agents, HN discussion mentioning manager/worker AI agent patterns.

5. Better approval/review ergonomics and safe autonomy controls.
- Users want granular approval policies (read-only, auto-accept for safe changes, review UX improvements).
- Evidence: Codex issues around approval modes, diff/review UX, and Cursor requests such as "Yolo mode for read-only commands" and review flow controls.

6. Cost/usage transparency and fairness on failures.
- Users care about usage predictability, especially when tasks fail.
- Evidence: Windsurf top-voted posts on credit refunds/rollover and failed-run charging frustration.

## Recommended v1.0.2 Feature Set

## P0 (Ship in v1.0.2)
[x] 1. Live Development Commentary Stream
- Stream concise step-by-step commentary while coding (plan -> action -> verification -> next step).
- Separate commentary from code/actions in the protocol and UI.
- Why: highest trust/value gain, directly addresses silent-agent frustration.

[x] 2. Agent Anti-Stall + Auto-Recovery
- Detect "stuck" states (repeated tool calls, no-progress loops, timeouts).
- Auto-recover by: retry strategy, tool backoff, summarize-and-continue, or explicit recovery prompt.
- Show recovery state in commentary timeline.

[x] 3. Execution Transparency Panel
- Show: selected model, tool invocations, active step, elapsed time, and token/cost estimate.
- Include explicit "why this action" snippets for each major step.

[x] 4. Safer Autonomy Modes
- Add clear execution modes: `read-only`, `review-required`, `auto-apply-safe`, `full-auto`.
- Add per-tool approval policy controls and visible current mode in UI.

[x] 5. Reliability Guardrails for Web/Tool Tasks
- Standardize tool schemas for strict providers.
- Add robust URL/tool validation and user-facing fallback messages.
- Add regression tests for schema compatibility across major model families.

## P1 (Start in v1.0.2, finish in v1.0.3 if needed)
[x] 6. Persistent Project Memory (Scoped)
- Lightweight persistent project summary + architecture notes that survive sessions.
- Used to prime future runs and reduce repeated context rebuilding.

[x] 7. Sub-Agent Framework (Minimal)
- Introduce a simple manager/worker abstraction for long tasks (planner agent + executor agent).
- Keep initial version behind a feature flag.

## Tool Schema Compatibility Matrix (v1.0.2)

| Provider    | Strict Tool Schema | Sample Models                                             | Result |
| ----------- | ------------------ | --------------------------------------------------------- | ------ |
| OpenAI      | Yes                | `gpt-5-codex`, `codex-mini-latest`, `gpt-4o`             | Pass   |
| Anthropic   | No                 | `claude-3-5-sonnet-latest`                               | Pass   |
| OpenRouter  | No                 | `openrouter/auto`                                         | Pass   |
| Together    | No                 | `meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo`           | Pass   |

Matrix data and live checks are exposed at:
- `/api/system/tool-schema-matrix`

## Acceptance Instrumentation (v1.0.2)

Instrumentation now emits and tracks:
- `commentaryFirstEventLatencyMs`
- `recoverySuccessRate` (aggregate)
- `manualInterventionRate` (aggregate)

Available via:
- stream data event: `run-metrics`
- system endpoint: `/api/system/agent-metrics`

## Suggested Acceptance Criteria
1. Commentary appears within 2 seconds of run start and updates at each meaningful step.
2. At least 90% of interrupted/stalled runs either recover automatically or produce a clear recovery suggestion.
3. Users can switch autonomy mode before and during a run; mode is reflected in every tool action.
4. Tool/schema compatibility tests pass for strict OpenAI Codex-style models and standard chat-completions models.
5. Timeline view logs model + tools + approvals + outcome for each run.

## Proposed v1.0.2 Success Metrics
- Reduce "agent got stuck" reports by at least 40%.
- Increase successful end-to-end task completion rate by at least 20%.
- Reduce average "manual continue" interventions per session.
- Increase user satisfaction on "I understand what the agent is doing".

## Sources (Playwright Browsed)
- https://forum.cursor.com/c/ideas
- https://forum.cursor.com/c/ideas/7
- https://codeium.canny.io/feature-requests
- https://news.ycombinator.com/item?id=44031432
- https://news.ycombinator.com/item?id=45534880
- https://github.com/openai/codex/issues
- https://github.com/features/copilot
- https://github.com/orgs/community/discussions/categories/copilot
- https://developers.openai.com/codex/
